{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# visualization\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score,matthews_corrcoef,classification_report,roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_data=pd.read_csv('../Data/creditcard.csv')\n",
    "cc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time      0\n",
       "v1        0\n",
       "v2        0\n",
       "v3        0\n",
       "v4        0\n",
       "v5        0\n",
       "v6        0\n",
       "v7        0\n",
       "v8        0\n",
       "v9        0\n",
       "v10       0\n",
       "v11       0\n",
       "v12       0\n",
       "v13       0\n",
       "v14       0\n",
       "v15       0\n",
       "v16       0\n",
       "v17       0\n",
       "v18       0\n",
       "v19       0\n",
       "v20       0\n",
       "v21       0\n",
       "v22       0\n",
       "v23       0\n",
       "v24       0\n",
       "v25       0\n",
       "v26       0\n",
       "v27       0\n",
       "v28       0\n",
       "amount    0\n",
       "class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make all colum names lower case for easy of use and check for missing values\n",
    "cc_data.columns = [x.lower() for x in cc_data.columns]\n",
    "cc_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    284807.000000\n",
       "mean         88.349619\n",
       "std         250.120109\n",
       "min           0.000000\n",
       "25%           5.600000\n",
       "50%          22.000000\n",
       "75%          77.165000\n",
       "max       25691.160000\n",
       "Name: amount, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop the time column\n",
    "cc_data.drop(['time'],axis=1,inplace=True)\n",
    "print(cc_data.shape)\n",
    "#quick overview of the amount column\n",
    "cc_data.amount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraudulent transaction : 0.1727485630620034 %\n",
      "valid transaction: 99.82725143693798 %\n",
      "There are a total of 492 fraudulent transactions\n"
     ]
    }
   ],
   "source": [
    "# find proportion of fraudulent transactions in the dataset\n",
    "fraud = cc_data.loc[cc_data['class'] == 1]\n",
    "valid = cc_data.loc[cc_data['class'] == 0]\n",
    "#calculate percentages\n",
    "p1= len(fraud)/len(cc_data)\n",
    "p2 = len(valid)/len(cc_data)\n",
    "print('fraudulent transaction :',p1*100,'%')\n",
    "print('valid transaction:',p2*100,'%')\n",
    "print('There are a total of',len(fraud),'fraudulent transactions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is heavily unbalanced, which is expected since most transactions are not fraudulent.\n",
    "If this becomes a problem later in the modeling stage, we can either doensample the majority class or upsample the minority class. Forn nor let's see how a baseline model performs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [ 30473  30496  31002 ... 284804 284805 284806] test: [    0     1     2 ... 57017 57018 57019]\n",
      "train: [     0      1      2 ... 284804 284805 284806] test: [ 30473  30496  31002 ... 113964 113965 113966]\n",
      "train: [     0      1      2 ... 284804 284805 284806] test: [ 81609  82400  83053 ... 170946 170947 170948]\n",
      "train: [     0      1      2 ... 284804 284805 284806] test: [150654 150660 150661 ... 227866 227867 227868]\n",
      "train: [     0      1      2 ... 227866 227867 227868] test: [212516 212644 213092 ... 284804 284805 284806]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "sss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "X = cc_data.drop(['class'], axis = 1)\n",
    "y = cc_data[\"class\"]\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"train:\", train_index, \"test:\", test_index)\n",
    "    original_X_train, original_X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     492.000000\n",
       "mean      122.211321\n",
       "std       256.683288\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         9.250000\n",
       "75%       105.890000\n",
       "max      2125.870000\n",
       "Name: amount, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#analyse the amount spent on fraudulent transactions\n",
    "fraud.amount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    284315.000000\n",
       "mean         88.291022\n",
       "std         250.105092\n",
       "min           0.000000\n",
       "25%           5.650000\n",
       "50%          22.000000\n",
       "75%          77.050000\n",
       "max       25691.160000\n",
       "Name: amount, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.amount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 25691.16)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "amount_val = cc_data['amount'].values\n",
    "sns.distplot(amount_val, color='blue')\n",
    "plt.title('Distribution of Transaction Amount')\n",
    "plt.xlim([min(cc_data.amount), max(cc_data.amount)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean average mean spent on fraudulent transactions is higher than for valid transactions: $122 vs $88. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 29)\n",
      "(284807,)\n"
     ]
    }
   ],
   "source": [
    "# seperate response variable from the explanatory variable\n",
    "X = cc_data.drop(['class'], axis = 1)\n",
    "y = cc_data[\"class\"]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing set\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers that we'll use\n",
    "classifiers = {\n",
    "    \"LogisiticR\": LogisticRegression(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"DecisionTree\": DecisionTreeClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suzet\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\suzet\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\suzet\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\suzet\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\suzet\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\suzet\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers:  LogisticRegression Has a training score of 100.0 % accuracy score\n",
      "Classifiers:  KNeighborsClassifier Has a training score of 100.0 % accuracy score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suzet\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-e0dc93d5271a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mtraining_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Classifiers: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Has a training score of\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"% accuracy score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    266\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "for key, classifier in classifiers.items():\n",
    "    classifier.fit(X_train, y_train)\n",
    "    training_score = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "    print(\"Classifiers: \", classifier.__class__.__name__, \"Has a training score of\", round(training_score.mean(), 2) * 100, \"% accuracy score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT = DecisionTreeClassifier(max_depth = 4, criterion = 'entropy')\n",
    "DT.fit(X_train, y_train)\n",
    "y_pred_dt = DT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56855    14]\n",
      " [   19    74]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56869\n",
      "           1       0.84      0.80      0.82        93\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.92      0.90      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_dt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
